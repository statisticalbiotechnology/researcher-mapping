{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from utils import pickle_obj, semantic_search_author, semantic_search_word, get_related_authors, get_related_words, translate_dict\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, show, output_notebook, output_file, save\n",
    "from bokeh.models import HoverTool, ColumnDataSource, value\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "from firebase_admin import credentials, firestore\n",
    "import firebase_admin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kth = pd.read_csv(\"assets/dataframes/all_authors_df_2004\")\n",
    "df_su = pd.read_csv(\"assets/dataframes/suDf\")\n",
    "df_uppsala = pd.read_csv(\"assets/dataframes/uppsalaDf\")\n",
    "df_sodertorn = pd.read_csv(\"assets/dataframes/sodertornDf\")\n",
    "\n",
    "df_kth = df_kth.rename(columns={\"KTH_id\": \"Auth_id\", \"KTH_name\": \"Auth_name\"})\n",
    "                    \n",
    "#df_auth = pd.read_csv(\"assets/dataframes/KT_auth_2004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nlp_data(df):\n",
    "    return df.Abstracts.values, df.Doc_id.values, df.Auth_id.values, df.Auth_name.values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_doc_kth, doc_id_kth, auth_kth, name_kth = get_nlp_data(df_kth)\n",
    "text_doc_su, doc_id_su, auth_su, name_su = get_nlp_data(df_su)\n",
    "text_doc_uppsala, doc_id_uppsala, auth_uppsala, name_uppsala = get_nlp_data(df_uppsala)\n",
    "text_doc_sodertorn, doc_id_sodertorn, auth_sodertorn, name_sodertorn = get_nlp_data(df_sodertorn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = np.concatenate([text_doc_kth, text_doc_su, text_doc_uppsala, text_doc_sodertorn])\n",
    "DOCID = np.concatenate([doc_id_kth, doc_id_su, doc_id_uppsala, doc_id_sodertorn]).astype(str)\n",
    "AUTHID = np.concatenate([auth_kth, auth_su, auth_uppsala, auth_sodertorn ])\n",
    "NAME = np.concatenate([name_kth, name_su, name_uppsala, name_sodertorn ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=list(zip(TEXT, AUTHID, DOCID, NAME)), columns=[\"Abstracts\", \"Auth_id\", \"Doc_id\", \"Auth_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstracts</th>\n",
       "      <th>Auth_id</th>\n",
       "      <th>Doc_id</th>\n",
       "      <th>Auth_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A model for the enhanced water dissociation th...</td>\n",
       "      <td>u16fm297:u13dx9f6</td>\n",
       "      <td>65923903</td>\n",
       "      <td>Dahlkild, Anders A.:Behm, Marten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Wood from white spruce Picea glauca that had ...</td>\n",
       "      <td>u16k1pmb:u1lkf75c</td>\n",
       "      <td>40520967</td>\n",
       "      <td>Zhang, Liming:Henriksson, Gunnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>We consider the moduli space H-g,H-n of n-poin...</td>\n",
       "      <td>u1mv0zlg</td>\n",
       "      <td>41290309</td>\n",
       "      <td>Bergstrom, Jonas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>In this paper a day-ahead planning algorithm f...</td>\n",
       "      <td>u16u3erw:u1naf2f4:u1fjok0u</td>\n",
       "      <td>40129874</td>\n",
       "      <td>Matevosyan, Julija:Olsson, Magnus:Soder, Lennart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>In this letter, we develop a fixed-point arith...</td>\n",
       "      <td>u1s42xk3:u12s8cr8</td>\n",
       "      <td>61385618</td>\n",
       "      <td>Johansson, Christopher:Lansner, Anders B.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140172</td>\n",
       "      <td>Cette contribution décrit l'évolution du mouve...</td>\n",
       "      <td>usodertorn4324</td>\n",
       "      <td>9191_sodertorn</td>\n",
       "      <td>Östberg, Kjell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140173</td>\n",
       "      <td>The first part gives a chronological overview ...</td>\n",
       "      <td>usodertorn4324</td>\n",
       "      <td>9204_sodertorn</td>\n",
       "      <td>Östberg, Kjell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140174</td>\n",
       "      <td>Det första fallet av aids i Sverige diagnostis...</td>\n",
       "      <td>usodertorn4324</td>\n",
       "      <td>9213_sodertorn</td>\n",
       "      <td>Östberg, Kjell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140175</td>\n",
       "      <td>For decades “Swedology” was a rich and polemic...</td>\n",
       "      <td>usodertorn4356</td>\n",
       "      <td>9218_sodertorn</td>\n",
       "      <td>Östlund, David</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140176</td>\n",
       "      <td>This article brings forward a set of examples ...</td>\n",
       "      <td>usodertorn4356</td>\n",
       "      <td>9221_sodertorn</td>\n",
       "      <td>Östlund, David</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140177 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Abstracts  \\\n",
       "0       A model for the enhanced water dissociation th...   \n",
       "1        Wood from white spruce Picea glauca that had ...   \n",
       "2       We consider the moduli space H-g,H-n of n-poin...   \n",
       "3       In this paper a day-ahead planning algorithm f...   \n",
       "4       In this letter, we develop a fixed-point arith...   \n",
       "...                                                   ...   \n",
       "140172  Cette contribution décrit l'évolution du mouve...   \n",
       "140173  The first part gives a chronological overview ...   \n",
       "140174  Det första fallet av aids i Sverige diagnostis...   \n",
       "140175  For decades “Swedology” was a rich and polemic...   \n",
       "140176  This article brings forward a set of examples ...   \n",
       "\n",
       "                           Auth_id          Doc_id  \\\n",
       "0                u16fm297:u13dx9f6        65923903   \n",
       "1                u16k1pmb:u1lkf75c        40520967   \n",
       "2                         u1mv0zlg        41290309   \n",
       "3       u16u3erw:u1naf2f4:u1fjok0u        40129874   \n",
       "4                u1s42xk3:u12s8cr8        61385618   \n",
       "...                            ...             ...   \n",
       "140172              usodertorn4324  9191_sodertorn   \n",
       "140173              usodertorn4324  9204_sodertorn   \n",
       "140174              usodertorn4324  9213_sodertorn   \n",
       "140175              usodertorn4356  9218_sodertorn   \n",
       "140176              usodertorn4356  9221_sodertorn   \n",
       "\n",
       "                                               Auth_name  \n",
       "0                       Dahlkild, Anders A.:Behm, Marten  \n",
       "1                       Zhang, Liming:Henriksson, Gunnar  \n",
       "2                                       Bergstrom, Jonas  \n",
       "3       Matevosyan, Julija:Olsson, Magnus:Soder, Lennart  \n",
       "4              Johansson, Christopher:Lansner, Anders B.  \n",
       "...                                                  ...  \n",
       "140172                                    Östberg, Kjell  \n",
       "140173                                    Östberg, Kjell  \n",
       "140174                                    Östberg, Kjell  \n",
       "140175                                    Östlund, David  \n",
       "140176                                    Östlund, David  \n",
       "\n",
       "[140177 rows x 4 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SU\t\t doc2vecModel\r\n",
      "SemiSupArray\t finalproduct\r\n",
      "assignmentStats  suNameId\r\n",
      "dataframes\t terran-fc671-firebase-adminsdk-k8xbh-0d575a0a99.json\r\n",
      "dictionaries\t uppsalaNameId\r\n",
      "divaScrape\t words.json\r\n",
      "diva_2004\t words.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"assets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"assets/df_all_schools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['uSU14622:uSU92268:uSU62150', 'uSU38475',\n",
       "       'uSU38475:uSU54522:uSU54709:uSU83623', ...,\n",
       "       'uSU9392:uSU15459:uSU86959', 'uSU79401', 'uSU79401'], dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth_su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'usu14622:usu92268:usu62150'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"uSU14622:uSU92268:uSU62150\".replace(\"uSU\", \"usu\").replace(\"uUppsala\", \"uuppsala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uuppsala160669:uuppsala3191:uuppsala133542:uuppsala64943:uuppsala167930'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'uUppsala160669:uUppsala3191:uUppsala133542:uUppsala64943:uUppsala167930'.replace(\"uUppsala\", \"uuppsala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "reformat_str = [v.replace(\"uSU\", \"usu\").replace(\"uUppsala\", \"uuppsala\") for v in df.Auth_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_to_id = dict(zip(df.Doc_id, reformat_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-e8813bdaa899>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "doc_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ekvall/kthLife/python\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auths_to_all_id_2004.pkl  id_to_auth_SU.pkl\t    id_to_auth_uppsala.pkl\r\n",
      "id_to_all_auths_2004.pkl  id_to_auth_sodertorn.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"assets/dictionaries/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(doc_to_id, open(\"./assets/dictionaries/doc_to_id.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"assets/dataframes/KTH_UPPSALA_SODERTORN_SU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(abstracts, doc, auth):\n",
    "    for d, w, a in zip(abstracts, doc, auth):\n",
    "        yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(d), [str(w)] + a.split(\":\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(TEXT, DOCID, AUTHID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocuabolary = list()\n",
    "for corpus in train_corpus:\n",
    "    vocuabolary +=  corpus.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = list(set(vocuabolary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_word =list()\n",
    "for w in unique_words:\n",
    "    dict_word.append({\"word\": w})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred = credentials.Certificate(\"./assets/terran-fc671-firebase-adminsdk-k8xbh-0d575a0a99.json\")\n",
    "app = firebase_admin.initialize_app(cred)\n",
    "\n",
    "store = firestore.client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "\n",
    "class EpochSaver(CallbackAny2Vec):\n",
    "    '''Callback to save model after each epoch.'''\n",
    "    \n",
    "    def __init__(self, path_prefix):\n",
    "        self.path_prefix = path_prefix\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        output_path = get_tmpfile('{}_epoch{}.model'.format(self.path_prefix, self.epoch))\n",
    "        model.save(output_path)\n",
    "        self.epoch += 1\n",
    "        \n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    '''Callback to log information about training'''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        \n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "    \n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Epoch #{} end\".format(self.epoch))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_logger = EpochLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=300, min_count=1, dm=0,\n",
    "                                      sample=1e-3, negative=15,hs=0,dbow_words=1,\n",
    "                                      max_vocab_size=None,workers=cores,window=10,\n",
    "                                          callbacks=[epoch_logger])\n",
    "\n",
    "model.build_vocab(train_corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have pre-trained a model with vectordim=500, and with 10_000 iterations. The rest of the hyper-parameters are the same as in the implementation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=1,report_delay=1)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "fname = get_tmpfile(\"my_doc2vec_model\")\n",
    "\n",
    "model.save(fname)\n",
    "model = gensim.models.doc2vec.Doc2Vec.load(fname)  # you can continue training with the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekvall/anaconda3/envs/kth-cluster/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "fname = get_tmpfile(\"doc2vec_more_school_1000\")\n",
    "model = gensim.models.doc2vec.Doc2Vec.load(fname)  # you can continue training with the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekvall/anaconda3/envs/kth-cluster/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "model.save(\"assets/doc2vecModel/more_school_1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec.load(get_tmpfile(\"doc2vec_more_school\"))  # you can continue training with the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=1,report_delay=1)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "324.3300178050995 * 1000 / 3600 / 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_search_author(sentence, model, df, topn=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train(train_corpus, total_examples=model.corpus_count, epochs=1,report_delay=1)\n",
    "#model = gensim.models.Word2Vec.load(\"assets/doc2vecModels/KTH2004_i10000_w10_d500_plainTrain/KTH2004_i10000_w10_d500_plainTrain.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dictonaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_o = pickle_obj()\n",
    "id_to_auth_kth = pickle_o.load(\"./assets/dictionaries/id_to_all_auths_2004\")\n",
    "id_to_auth_SU = pickle_o.load(\"./assets/dictionaries/id_to_auth_SU\")\n",
    "id_to_auth_uppsala = pickle_o.load(\"./assets/dictionaries/id_to_auth_uppsala\")\n",
    "id_to_auth_sodertorn = pickle_o.load(\"./assets/dictionaries/id_to_auth_sodertorn\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_auth = {}\n",
    "for d in (id_to_auth, id_to_auth_SU, id_to_auth_uppsala, id_to_auth_sodertorn): \n",
    "    id_to_auth.update(d)\n",
    "auth_to_id = {k:v for v, k in id_to_auth.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search_author(sentence, model, df, topn=30):                      \n",
    "    word_2_vec = 0                                                             \n",
    "    for word in sentence:                                                      \n",
    "        word_2_vec += model[str(word)]                                         \n",
    "    for a in model.docvecs.most_similar( [ word_2_vec ], topn=topn):           \n",
    "        if a[0][0] !=\"u\":                                                      \n",
    "            print(str(a[0]),\"||\",get_article_authors_name(str(a[0]),df),\" || \", np.around(a[1],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_authors_name(doc_id, df):                                      \n",
    "    name = \"\"                                                                  \n",
    "    if len(df[df.Doc_id == doc_id].Auth_name) > 0:                              \n",
    "        name_list = df[df.Doc_id == doc_id].Auth_name.values[0].split(\":\")      \n",
    "        for i, n in enumerate(name_list):                                      \n",
    "            if i == 0:                                                         \n",
    "                name += str(n)                                                 \n",
    "            elif i == len(name_list) - 1 and i > 1:                            \n",
    "                name += \" and \" + str(n)                                       \n",
    "            elif i > 1:                                                        \n",
    "                name += \" , \" + str(n)                                         \n",
    "    else:                                                                      \n",
    "        name = \"NaN\"                                                           \n",
    "                                                                               \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the success of the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic serach after authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [\"dogs\",\"forensic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Doc_id == \"38852_SU\"].Abstracts.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_search_author(sentence, model, df, topn=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_article_authors_name(str(a[0]),df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_search_author(sentence, model, df, topn=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic serach after authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_search_word(sentence, model, df, topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for related authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_related_authors(\"Kall, Lukas(u1gqsept)\",model, auth_to_id, id_to_auth, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_related_authors(\"Savolainen, Peter\",model, auth_to_id, id_to_auth, topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_related_words(\"Kall, Lukas(u1gqsept)\", model, auth_to_id, id_to_auth, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_related_words(\"Savolainen, Peter\", model, auth_to_id, id_to_auth, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_related_words(\"Hudson, Paul\", model, auth_to_id, id_to_auth, topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a plot of the tSNE manifold to verify a underlying structure of the authorvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all authors-ids and its vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = list()\n",
    "docVec = list()\n",
    "for k, v in zip(model.docvecs.doctags.keys(), model.docvecs.doctag_syn0): \n",
    "    if k[0] == \"u\":\n",
    "        cat.append(id_to_auth[k])\n",
    "        docVec.append(v)\n",
    "docVec = np.asarray(docVec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find what department author is a member of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_names = list()\n",
    "for n in cat: \n",
    "    if 0 < df_auth[df_auth.Name.str.contains(str(n))].dep_name.describe().unique()[0]:\n",
    "        dep_names.append(df_auth[df_auth.Name.str.contains(str(n))].dep_name.describe().top)\n",
    "    else:\n",
    "        dep_names.append(\"nan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that the deprtment names have is trandlated into ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_names = np.asarray(dep_names)\n",
    "name_dict = dict()\n",
    "for u_id in np.unique(dep_names):\n",
    "    n = str()\n",
    "    if u_id is np.nan:\n",
    "        u_id = str(u_id)\n",
    "    for l in u_id:\n",
    "        if ord(l) < 128:\n",
    "            n +=l\n",
    "        else:\n",
    "            n += translate_dict[l]\n",
    "    name_dict[str(u_id)] = str(n)\n",
    "    \n",
    "asci_cat = list()\n",
    "for c in dep_names:asci_cat.append(name_dict[str(c)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make tSNE over author vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_input = docVec\n",
    "tsne_input = pd.DataFrame(tsne_input, index=asci_cat)\n",
    "tsne_input = tsne_input\n",
    "tsne = TSNE(perplexity=5)\n",
    "%time tsne_vectors = tsne.fit_transform(tsne_input)\n",
    "tsne_vectors = pd.DataFrame(tsne_vectors,\n",
    "                            index=pd.Index(tsne_input.index),\n",
    "                            columns=[u'x_coord', u'y_coord'])\n",
    "tsne_vectors[u'word'] = tsne_vectors.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The plot seems to have an underlying structure, check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "# add our DataFrame as a ColumnDataSource for Bokeh\n",
    "plot_data = ColumnDataSource(tsne_vectors)\n",
    "\n",
    "# create the plot and configure the\n",
    "# title, dimensions, and tools\n",
    "tsne_plot = figure(title=u't-SNE Word Embeddings',\n",
    "                   plot_width = 800,\n",
    "                   plot_height = 800,\n",
    "                   tools= (u'pan, wheel_zoom, box_zoom,'\n",
    "                           u'box_select, reset'),\n",
    "                   active_scroll=u'wheel_zoom')\n",
    "\n",
    "# add a hover tool to display words on roll-over\n",
    "tsne_plot.add_tools( HoverTool(tooltips = u'@word') )\n",
    "\n",
    "# draw the words as circles on the plot\n",
    "tsne_plot.circle(u'x_coord', u'y_coord', source=plot_data,\n",
    "                 color=u'blue', line_alpha=0.2, fill_alpha=0.1,\n",
    "                 size=10, hover_line_color=u'black')\n",
    "\n",
    "\n",
    "tsne_plot.xaxis.visible = False\n",
    "tsne_plot.yaxis.visible = False\n",
    "tsne_plot.grid.grid_line_color = None\n",
    "tsne_plot.outline_line_color = None\n",
    "\n",
    "# engage!\n",
    "show(tsne_plot);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file(\"./assets/figures/tSNEauthors.html\")\n",
    "save(tsne_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing some SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_U(V, comp=90):\n",
    "    U, _, _ = svds(V, k=comp)\n",
    "    norms = np.sqrt(np.sum(np.square(U), axis=1, keepdims=True))\n",
    "    U /= np.maximum(norms, 1e-7)\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = get_U(model.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = model.wv.index2word\n",
    "x2i = {w:i for i, w in enumerate(words)}\n",
    "i2x = {i:w for i, w in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "for x in ['dogs', 'biofuels', 'peptide',\"percolator\",\"forensic\",\"economic\",\n",
    "          \"finance\",\"algebra\",\"convergence\",\"bacteria\"]:\n",
    "\n",
    "    dd = cosine_similarity(U,U[x2i[x]].reshape(1,-1)).flatten()\n",
    "    s = ''\n",
    "    for i in np.argsort(dd)[::-1][:k + 1]:\n",
    "        if i2x[i] == x: continue\n",
    "        xy = tuple(sorted((x, i2x[i])))\n",
    "        s += '(%s, %.3lf) ' % (i2x[i], dd[i])\n",
    "    print('%s, %s' % (x, s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ua = get_U(model.docvecs.doctag_syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = model.docvecs.index2entity\n",
    "x2iA = {w:i for i, w in enumerate(authors)}\n",
    "i2xA = {i:w for i, w in enumerate(authors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 15\n",
    "for x in [\"Kall, Lukas(u1gqsept)\", \"Savolainen, Peter\", \"Hudson, Paul\"]:\n",
    "\n",
    "    dd = cosine_similarity(Ua,Ua[x2iA[auth_to_id[str(x)]]].reshape(1,-1)).flatten()\n",
    "    s = ''\n",
    "    for i in np.argsort(dd)[::-1][:k + 1]:\n",
    "        if i2xA[i] == auth_to_id[str(x)]: \n",
    "            continue\n",
    "\n",
    "        if i2xA[i][0] == \"u\":\n",
    "            s += '(%s, %.3lf) ' % (id_to_auth[i2xA[i]], dd[i])\n",
    "    print('%s, %s' % (x, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ub = get_U(np.concatenate((model.docvecs.doctag_syn0, model.wv.vectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both = authors + words\n",
    "x2iB = {w:i for i, w in enumerate(both)}\n",
    "i2xB = {i:w for i, w in enumerate(both)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 25\n",
    "for x in [\"Kall, Lukas(u1gqsept)\", \"Savolainen, Peter\", \"Hudson, Paul\"]:\n",
    "\n",
    "    dd = cosine_similarity(Ub,Ub[x2iB[auth_to_id[str(x)]]].reshape(1,-1)).flatten()\n",
    "    s = ''\n",
    "    for i in np.argsort(dd)[::-1][:k + 1]:\n",
    "        if i2xB[i] == x: continue\n",
    "        try:\n",
    "            int(i2xB[i][0])\n",
    "        except:\n",
    "            if not i2xB[i][0] == \"u\" and not i2xB[i][1] == \"l\":\n",
    "                s += '(%s, %.3lf) ' % (i2xB[i], dd[i])\n",
    "    print('%s, %s' % (x, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python kth-cluster",
   "language": "python",
   "name": "kth-cluster"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
